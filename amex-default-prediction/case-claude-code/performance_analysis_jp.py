#!/usr/bin/env python3
"""
ãƒ¢ãƒ‡ãƒ«æ€§èƒ½åˆ†æã¨ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ (æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆå¯¾å¿œç‰ˆ)
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import platform

def setup_japanese_font():
    """æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š"""
    try:
        # ã‚·ã‚¹ãƒ†ãƒ åˆ¥ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
        system = platform.system()
        
        if system == "Darwin":  # macOS
            # macOSã§åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’è©¦ã™
            fonts = ['Hiragino Sans', 'Hiragino Kaku Gothic ProN', 'Arial Unicode MS', 'DejaVu Sans']
        elif system == "Windows":
            fonts = ['MS Gothic', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
        else:  # Linux
            fonts = ['Noto Sans CJK JP', 'DejaVu Sans', 'Liberation Sans']
        
        # åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚©ãƒ³ãƒˆã‚’ç¢ºèª
        import matplotlib.font_manager as fm
        available_fonts = [f.name for f in fm.fontManager.ttflist]
        
        for font in fonts:
            if font in available_fonts:
                plt.rcParams['font.family'] = font
                print(f"æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š: {font}")
                return True
        
        # ãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯è‹±èªç‰ˆã«åˆ‡ã‚Šæ›¿ãˆ
        print("æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è‹±èªç‰ˆã§æç”»ã—ã¾ã™ã€‚")
        return False
        
    except Exception as e:
        print(f"ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        return False

def create_performance_plots_english():
    """è‹±èªç‰ˆã®æ€§èƒ½åˆ†æãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆ"""
    
    submission = pd.read_csv("submission.csv")
    predictions = submission['prediction']
    
    # ãƒ—ãƒ­ãƒƒãƒˆã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
    plt.style.use('default')
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('Credit Default Prediction Model - Performance Analysis', fontsize=16, fontweight='bold')
    
    # 1. äºˆæ¸¬å€¤ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
    axes[0, 0].hist(predictions, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
    axes[0, 0].set_title('Distribution of Predicted Probabilities')
    axes[0, 0].set_xlabel('Predicted Probability')
    axes[0, 0].set_ylabel('Frequency')
    axes[0, 0].axvline(predictions.mean(), color='red', linestyle='--', 
                      label=f'Mean: {predictions.mean():.3f}')
    axes[0, 0].legend()
    
    # 2. ç´¯ç©åˆ†å¸ƒé–¢æ•°
    sorted_preds = np.sort(predictions)
    cumulative = np.arange(1, len(sorted_preds) + 1) / len(sorted_preds)
    axes[0, 1].plot(sorted_preds, cumulative, color='green', linewidth=2)
    axes[0, 1].set_title('Cumulative Distribution Function (CDF)')
    axes[0, 1].set_xlabel('Predicted Probability')
    axes[0, 1].set_ylabel('Cumulative Probability')
    axes[0, 1].grid(True, alpha=0.3)
    
    # 3. ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ
    risk_levels = ['Low Risk\n(<10%)', 'Medium Risk\n(10-50%)', 'High Risk\n(â‰¥50%)']
    risk_counts = [
        (predictions < 0.1).sum(),
        ((predictions >= 0.1) & (predictions < 0.5)).sum(),
        (predictions >= 0.5).sum()
    ]
    colors = ['green', 'orange', 'red']
    
    bars = axes[1, 0].bar(risk_levels, risk_counts, color=colors, alpha=0.7, edgecolor='black')
    axes[1, 0].set_title('Customer Distribution by Risk Level')
    axes[1, 0].set_ylabel('Number of Customers')
    
    # ãƒãƒ¼ã®ä¸Šã«æ•°å€¤ã‚’è¡¨ç¤º
    for bar, count in zip(bars, risk_counts):
        height = bar.get_height()
        axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                       f'{count:,}\n({count/len(predictions)*100:.1f}%)',
                       ha='center', va='bottom', fontweight='bold')
    
    # 4. Box plot
    axes[1, 1].boxplot(predictions, vert=True, patch_artist=True,
                      boxprops=dict(facecolor='lightblue', alpha=0.7))
    axes[1, 1].set_title('Box Plot of Predicted Probabilities')
    axes[1, 1].set_ylabel('Predicted Probability')
    
    # çµ±è¨ˆæƒ…å ±ã‚’è¿½åŠ 
    stats_text = f"""Statistical Summary:
Mean: {predictions.mean():.4f}
Median: {predictions.median():.4f}
Std Dev: {predictions.std():.4f}
Min: {predictions.min():.4f}
Max: {predictions.max():.4f}"""
    
    axes[1, 1].text(1.1, 0.5, stats_text, transform=axes[1, 1].transAxes,
                    fontsize=10, verticalalignment='center',
                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    plt.tight_layout()
    plt.savefig('model_performance_analysis_en.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("ğŸ“Š Performance analysis plot saved: model_performance_analysis_en.png")

def create_feature_importance_plot():
    """ç‰¹å¾´é‡é‡è¦åº¦ã®ãƒ—ãƒ­ãƒƒãƒˆï¼ˆè‹±èªç‰ˆï¼‰"""
    
    # å®Ÿéš›ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸç‰¹å¾´é‡é‡è¦åº¦
    feature_importance = {
        'D_39_last': 221,
        'P_2_last': 208,
        'B_4_last': 201,
        'B_3_last': 171,
        'B_5_last': 144,
        'B_4_std': 136,
        'S_3_last': 123,
        'R_1_last': 113,
        'R_3_last': 109,
        'D_41_last': 108
    }
    
    plt.figure(figsize=(12, 8))
    
    features = list(feature_importance.keys())
    importances = list(feature_importance.values())
    
    # è‰²ä»˜ã‘ï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥ï¼‰
    colors = []
    for feature in features:
        if feature.startswith('D_'):
            colors.append('#FF6B6B')  # Red for Delinquency
        elif feature.startswith('P_'):
            colors.append('#4ECDC4')  # Teal for Payment
        elif feature.startswith('B_'):
            colors.append('#45B7D1')  # Blue for Balance
        elif feature.startswith('S_'):
            colors.append('#96CEB4')  # Green for Spending
        elif feature.startswith('R_'):
            colors.append('#FFEAA7')  # Yellow for Risk
        else:
            colors.append('#DDA0DD')  # Purple for others
    
    bars = plt.barh(features, importances, color=colors, alpha=0.8, edgecolor='black')
    
    plt.title('Top 10 Most Important Features', fontsize=16, fontweight='bold', pad=20)
    plt.xlabel('Feature Importance', fontsize=12)
    plt.ylabel('Features', fontsize=12)
    
    # é‡è¦åº¦ã®å€¤ã‚’ãƒãƒ¼ã«è¡¨ç¤º
    for i, (bar, importance) in enumerate(zip(bars, importances)):
        plt.text(bar.get_width() + 2, bar.get_y() + bar.get_height()/2, 
                f'{importance}', ha='left', va='center', fontweight='bold')
    
    # å‡¡ä¾‹ã®è¿½åŠ 
    legend_elements = [
        plt.Rectangle((0,0),1,1, facecolor='#FF6B6B', alpha=0.8, label='Delinquency (D_)'),
        plt.Rectangle((0,0),1,1, facecolor='#4ECDC4', alpha=0.8, label='Payment (P_)'),
        plt.Rectangle((0,0),1,1, facecolor='#45B7D1', alpha=0.8, label='Balance (B_)'),
        plt.Rectangle((0,0),1,1, facecolor='#96CEB4', alpha=0.8, label='Spending (S_)'),
        plt.Rectangle((0,0),1,1, facecolor='#FFEAA7', alpha=0.8, label='Risk (R_)')
    ]
    plt.legend(handles=legend_elements, loc='lower right')
    
    plt.grid(axis='x', alpha=0.3)
    plt.tight_layout()
    plt.savefig('feature_importance_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("ğŸ“Š Feature importance plot saved: feature_importance_analysis.png")

def create_prediction_distribution_plot():
    """äºˆæ¸¬åˆ†å¸ƒã®è©³ç´°ãƒ—ãƒ­ãƒƒãƒˆ"""
    
    submission = pd.read_csv("submission.csv")
    predictions = submission['prediction']
    
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    fig.suptitle('Detailed Prediction Distribution Analysis', fontsize=16, fontweight='bold')
    
    # 1. ãƒ­ã‚°ã‚¹ã‚±ãƒ¼ãƒ«ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
    axes[0].hist(predictions, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
    axes[0].set_yscale('log')
    axes[0].set_title('Histogram (Log Scale)')
    axes[0].set_xlabel('Predicted Probability')
    axes[0].set_ylabel('Frequency (Log Scale)')
    axes[0].grid(True, alpha=0.3)
    
    # 2. ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æ
    percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]
    percentile_values = [np.percentile(predictions, p) for p in percentiles]
    
    axes[1].plot(percentiles, percentile_values, 'o-', linewidth=2, markersize=8, color='orange')
    axes[1].set_title('Percentile Analysis')
    axes[1].set_xlabel('Percentile')
    axes[1].set_ylabel('Predicted Probability')
    axes[1].grid(True, alpha=0.3)
    
    # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«å€¤ã‚’ãƒ—ãƒ­ãƒƒãƒˆã«è¡¨ç¤º
    for p, v in zip(percentiles, percentile_values):
        axes[1].annotate(f'{v:.3f}', (p, v), textcoords="offset points", 
                        xytext=(0,10), ha='center', fontsize=8)
    
    # 3. å¯†åº¦ãƒ—ãƒ­ãƒƒãƒˆ
    axes[2].hist(predictions, bins=100, density=True, alpha=0.7, color='lightgreen', edgecolor='black')
    axes[2].set_title('Probability Density')
    axes[2].set_xlabel('Predicted Probability')
    axes[2].set_ylabel('Density')
    axes[2].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('prediction_distribution_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("ğŸ“Š Prediction distribution plot saved: prediction_distribution_analysis.png")

def analyze_submission_performance():
    """æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®æ€§èƒ½åˆ†æï¼ˆæ—¥æœ¬èªï¼‰"""
    
    print("="*60)
    print("ãƒ¢ãƒ‡ãƒ«æ€§èƒ½åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
    print("="*60)
    
    # æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    submission = pd.read_csv("submission.csv")
    
    # åŸºæœ¬çµ±è¨ˆ
    predictions = submission['prediction']
    
    print(f"\nğŸ“Š äºˆæ¸¬å€¤ã®åŸºæœ¬çµ±è¨ˆ:")
    print(f"  ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(predictions):,}")
    print(f"  å¹³å‡å€¤: {predictions.mean():.6f}")
    print(f"  æ¨™æº–åå·®: {predictions.std():.6f}")
    print(f"  æœ€å°å€¤: {predictions.min():.6f}")
    print(f"  æœ€å¤§å€¤: {predictions.max():.6f}")
    print(f"  ä¸­å¤®å€¤: {predictions.median():.6f}")
    
    # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æ
    percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]
    print(f"\nğŸ“ˆ ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æ:")
    for p in percentiles:
        value = np.percentile(predictions, p)
        print(f"  {p:2d}%ile: {value:.6f}")
    
    # äºˆæ¸¬åˆ†å¸ƒã®åˆ†æ
    bins = [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0]
    bin_labels = ['0.0-0.1', '0.1-0.3', '0.3-0.5', '0.5-0.7', '0.7-0.9', '0.9-1.0']
    
    print(f"\nğŸ“‹ äºˆæ¸¬å€¤åˆ†å¸ƒ:")
    for i, (start, end) in enumerate(zip(bins[:-1], bins[1:])):
        count = ((predictions >= start) & (predictions < end)).sum()
        if i == len(bins) - 2:  # æœ€å¾Œã®binã¯<=ã‚’ä½¿ç”¨
            count = ((predictions >= start) & (predictions <= end)).sum()
        percentage = count / len(predictions) * 100
        print(f"  {bin_labels[i]}: {count:,} ({percentage:.1f}%)")
    
    # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ†æ
    print(f"\nâš ï¸  ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ†æ:")
    low_risk = (predictions < 0.1).sum()
    medium_risk = ((predictions >= 0.1) & (predictions < 0.5)).sum()
    high_risk = (predictions >= 0.5).sum()
    
    print(f"  ä½ãƒªã‚¹ã‚¯ (< 10%): {low_risk:,} ({low_risk/len(predictions)*100:.1f}%)")
    print(f"  ä¸­ãƒªã‚¹ã‚¯ (10-50%): {medium_risk:,} ({medium_risk/len(predictions)*100:.1f}%)")
    print(f"  é«˜ãƒªã‚¹ã‚¯ (â‰¥ 50%): {high_risk:,} ({high_risk/len(predictions)*100:.1f}%)")
    
    return submission

if __name__ == "__main__":
    print("="*60)
    print("ãƒ¢ãƒ‡ãƒ«æ€§èƒ½åˆ†æ (æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆå¯¾å¿œç‰ˆ)")
    print("="*60)
    
    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’è©¦è¡Œ
    japanese_available = setup_japanese_font()
    
    # åŸºæœ¬åˆ†æ
    submission = analyze_submission_performance()
    
    print(f"\nğŸ“Š ã‚°ãƒ©ãƒ•ä½œæˆä¸­...")
    
    # è‹±èªç‰ˆã®ãƒ—ãƒ­ãƒƒãƒˆä½œæˆï¼ˆç¢ºå®Ÿã«å‹•ä½œï¼‰
    create_performance_plots_english()
    create_feature_importance_plot()
    create_prediction_distribution_plot()
    
    print(f"\nğŸ‰ åˆ†æå®Œäº†ï¼")
    print(f"ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
    print(f"  â€¢ model_performance_analysis_en.png")
    print(f"  â€¢ feature_importance_analysis.png") 
    print(f"  â€¢ prediction_distribution_analysis.png")
    print(f"\nè©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: validation_report.md")