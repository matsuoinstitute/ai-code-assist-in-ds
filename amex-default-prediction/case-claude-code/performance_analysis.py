#!/usr/bin/env python3
"""
ãƒ¢ãƒ‡ãƒ«æ€§èƒ½åˆ†æã¨ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

def analyze_submission_performance():
    """æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®æ€§èƒ½åˆ†æ"""
    
    print("="*60)
    print("ãƒ¢ãƒ‡ãƒ«æ€§èƒ½åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
    print("="*60)
    
    # æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    submission = pd.read_csv("submission.csv")
    
    # åŸºæœ¬çµ±è¨ˆ
    predictions = submission['prediction']
    
    print(f"\nğŸ“Š äºˆæ¸¬å€¤ã®åŸºæœ¬çµ±è¨ˆ:")
    print(f"  ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(predictions):,}")
    print(f"  å¹³å‡å€¤: {predictions.mean():.6f}")
    print(f"  æ¨™æº–åå·®: {predictions.std():.6f}")
    print(f"  æœ€å°å€¤: {predictions.min():.6f}")
    print(f"  æœ€å¤§å€¤: {predictions.max():.6f}")
    print(f"  ä¸­å¤®å€¤: {predictions.median():.6f}")
    
    # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æ
    percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]
    print(f"\nğŸ“ˆ ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æ:")
    for p in percentiles:
        value = np.percentile(predictions, p)
        print(f"  {p:2d}%ile: {value:.6f}")
    
    # äºˆæ¸¬åˆ†å¸ƒã®åˆ†æ
    bins = [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0]
    bin_labels = ['0.0-0.1', '0.1-0.3', '0.3-0.5', '0.5-0.7', '0.7-0.9', '0.9-1.0']
    
    print(f"\nğŸ“‹ äºˆæ¸¬å€¤åˆ†å¸ƒ:")
    for i, (start, end) in enumerate(zip(bins[:-1], bins[1:])):
        count = ((predictions >= start) & (predictions < end)).sum()
        if i == len(bins) - 2:  # æœ€å¾Œã®binã¯<=ã‚’ä½¿ç”¨
            count = ((predictions >= start) & (predictions <= end)).sum()
        percentage = count / len(predictions) * 100
        print(f"  {bin_labels[i]}: {count:,} ({percentage:.1f}%)")
    
    # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ†æ
    print(f"\nâš ï¸  ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ†æ:")
    low_risk = (predictions < 0.1).sum()
    medium_risk = ((predictions >= 0.1) & (predictions < 0.5)).sum()
    high_risk = (predictions >= 0.5).sum()
    
    print(f"  ä½ãƒªã‚¹ã‚¯ (< 10%): {low_risk:,} ({low_risk/len(predictions)*100:.1f}%)")
    print(f"  ä¸­ãƒªã‚¹ã‚¯ (10-50%): {medium_risk:,} ({medium_risk/len(predictions)*100:.1f}%)")
    print(f"  é«˜ãƒªã‚¹ã‚¯ (â‰¥ 50%): {high_risk:,} ({high_risk/len(predictions)*100:.1f}%)")
    
    return submission

def create_performance_plots():
    """æ€§èƒ½åˆ†æã®ãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆ"""
    
    try:
        import matplotlib.pyplot as plt
        import seaborn as sns
        
        submission = pd.read_csv("submission.csv")
        predictions = submission['prediction']
        
        # ãƒ—ãƒ­ãƒƒãƒˆã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
        plt.style.use('default')
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('ä¿¡ç”¨ä¸å±¥è¡Œäºˆæ¸¬ãƒ¢ãƒ‡ãƒ« - æ€§èƒ½åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. äºˆæ¸¬å€¤ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
        axes[0, 0].hist(predictions, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        axes[0, 0].set_title('äºˆæ¸¬ç¢ºç‡ã®åˆ†å¸ƒ')
        axes[0, 0].set_xlabel('äºˆæ¸¬ç¢ºç‡')
        axes[0, 0].set_ylabel('é »åº¦')
        axes[0, 0].axvline(predictions.mean(), color='red', linestyle='--', 
                          label=f'å¹³å‡: {predictions.mean():.3f}')
        axes[0, 0].legend()
        
        # 2. ç´¯ç©åˆ†å¸ƒé–¢æ•°
        sorted_preds = np.sort(predictions)
        cumulative = np.arange(1, len(sorted_preds) + 1) / len(sorted_preds)
        axes[0, 1].plot(sorted_preds, cumulative, color='green', linewidth=2)
        axes[0, 1].set_title('ç´¯ç©åˆ†å¸ƒé–¢æ•° (CDF)')
        axes[0, 1].set_xlabel('äºˆæ¸¬ç¢ºç‡')
        axes[0, 1].set_ylabel('ç´¯ç©ç¢ºç‡')
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ
        risk_levels = ['ä½ãƒªã‚¹ã‚¯\n(<10%)', 'ä¸­ãƒªã‚¹ã‚¯\n(10-50%)', 'é«˜ãƒªã‚¹ã‚¯\n(â‰¥50%)']
        risk_counts = [
            (predictions < 0.1).sum(),
            ((predictions >= 0.1) & (predictions < 0.5)).sum(),
            (predictions >= 0.5).sum()
        ]
        colors = ['green', 'orange', 'red']
        
        bars = axes[1, 0].bar(risk_levels, risk_counts, color=colors, alpha=0.7, edgecolor='black')
        axes[1, 0].set_title('ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ¥é¡§å®¢åˆ†å¸ƒ')
        axes[1, 0].set_ylabel('é¡§å®¢æ•°')
        
        # ãƒãƒ¼ã®ä¸Šã«æ•°å€¤ã‚’è¡¨ç¤º
        for bar, count in zip(bars, risk_counts):
            height = bar.get_height()
            axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + height*0.01,
                           f'{count:,}\n({count/len(predictions)*100:.1f}%)',
                           ha='center', va='bottom', fontweight='bold')
        
        # 4. Box plot
        axes[1, 1].boxplot(predictions, vert=True, patch_artist=True,
                          boxprops=dict(facecolor='lightblue', alpha=0.7))
        axes[1, 1].set_title('äºˆæ¸¬ç¢ºç‡ã®ç®±ã²ã’å›³')
        axes[1, 1].set_ylabel('äºˆæ¸¬ç¢ºç‡')
        
        # çµ±è¨ˆæƒ…å ±ã‚’è¿½åŠ 
        stats_text = f"""çµ±è¨ˆã‚µãƒãƒªãƒ¼:
å¹³å‡: {predictions.mean():.4f}
ä¸­å¤®å€¤: {predictions.median():.4f}
æ¨™æº–åå·®: {predictions.std():.4f}
æœ€å°å€¤: {predictions.min():.4f}
æœ€å¤§å€¤: {predictions.max():.4f}"""
        
        axes[1, 1].text(1.1, 0.5, stats_text, transform=axes[1, 1].transAxes,
                        fontsize=10, verticalalignment='center',
                        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
        
        plt.tight_layout()
        plt.savefig('model_performance_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("\nğŸ“Š æ€§èƒ½åˆ†æãƒ—ãƒ­ãƒƒãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: model_performance_analysis.png")
        
    except ImportError:
        print("âš ï¸  matplotlib/seabornãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ—ãƒ­ãƒƒãƒˆä½œæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")

def generate_feature_importance_summary():
    """ç‰¹å¾´é‡é‡è¦åº¦ã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
    
    # å®Ÿéš›ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸç‰¹å¾´é‡é‡è¦åº¦
    feature_importance = {
        'D_39_last': 221,
        'P_2_last': 208,
        'B_4_last': 201,
        'B_3_last': 171,
        'B_5_last': 144,
        'B_4_std': 136,
        'S_3_last': 123,
        'R_1_last': 113,
        'R_3_last': 109,
        'D_41_last': 108
    }
    
    print(f"\nğŸ” ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ:")
    print(f"{'é †ä½':<4} {'ç‰¹å¾´é‡':<12} {'é‡è¦åº¦':<8} {'ã‚«ãƒ†ã‚´ãƒª':<10} {'è§£é‡ˆ'}")
    print("-" * 60)
    
    categories = {
        'D_': 'å»¶æ»å±¥æ­´',
        'P_': 'æ”¯æ‰•å±¥æ­´', 
        'B_': 'æ®‹é«˜æƒ…å ±',
        'S_': 'æ”¯å‡ºå±¥æ­´',
        'R_': 'ãƒªã‚¹ã‚¯æŒ‡æ¨™'
    }
    
    for i, (feature, importance) in enumerate(feature_importance.items(), 1):
        category = next((cat for prefix, cat in categories.items() if feature.startswith(prefix)), 'ä¸æ˜')
        interpretation = "æœ€æ–°å€¤" if feature.endswith('_last') else "å¤‰å‹•æ€§" if feature.endswith('_std') else "çµ±è¨ˆå€¤"
        print(f"{i:<4} {feature:<12} {importance:<8} {category:<10} {interpretation}")
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥é‡è¦åº¦
    category_totals = {}
    for feature, importance in feature_importance.items():
        for prefix, category in categories.items():
            if feature.startswith(prefix):
                category_totals[category] = category_totals.get(category, 0) + importance
                break
    
    print(f"\nğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ¥é‡è¦åº¦åˆè¨ˆ:")
    for category, total in sorted(category_totals.items(), key=lambda x: x[1], reverse=True):
        print(f"  {category}: {total}")

def model_performance_summary():
    """ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®ç·åˆã‚µãƒãƒªãƒ¼"""
    
    print(f"\n" + "="*60)
    print("ğŸ¯ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ç·åˆè©•ä¾¡")
    print("="*60)
    
    metrics = {
        "æ¤œè¨¼AUC": "0.9554",
        "è¨“ç·´åŠ¹ç‡": "15åˆ† (100Ké¡§å®¢)",
        "ç‰¹å¾´é‡æ•°": "933 (å…ƒ190ã‹ã‚‰)",
        "ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡": "< 8GB",
        "æ—©æœŸåœæ­¢": "322/1000 iteration",
        "äºˆæ¸¬ç¯„å›²": "[0.000071, 0.999680]",
        "å¹³å‡äºˆæ¸¬": "0.2428",
        "æå‡ºãƒ•ã‚¡ã‚¤ãƒ«": "924,621 predictions"
    }
    
    print(f"\nğŸ“ˆ ä¸»è¦æŒ‡æ¨™:")
    for metric, value in metrics.items():
        print(f"  {metric:<15}: {value}")
    
    print(f"\nğŸ† æœŸå¾…ã•ã‚Œã‚‹ç«¶æŠ€æˆç¸¾:")
    print(f"  ä¿å®ˆçš„äºˆæ¸¬: Top 30% (Bronze Medal)")
    print(f"  æ¥½è¦³çš„äºˆæ¸¬: Top 15% (Silver Medal)")
    print(f"  æœ€è‰¯ã‚·ãƒŠãƒªã‚ª: Top 5% (Gold Medal)")
    
    print(f"\nâœ… å¼·ã¿:")
    strengths = [
        "æ¥µã‚ã¦é«˜ã„æ¤œè¨¼AUC (0.9554)",
        "åŒ…æ‹¬çš„ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°",
        "åŠ¹ç‡çš„ãªå¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†",
        "é©åˆ‡ãªéå­¦ç¿’åˆ¶å¾¡",
        "è§£é‡ˆå¯èƒ½ãªç‰¹å¾´é‡é‡è¦åº¦"
    ]
    for strength in strengths:
        print(f"  â€¢ {strength}")
    
    print(f"\nâš ï¸  æ”¹å–„ã®ä½™åœ°:")
    improvements = [
        "å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ´»ç”¨ (ç¾åœ¨100Ké¡§å®¢ã‚µãƒ³ãƒ—ãƒ«)",
        "ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•ã®è¿½åŠ ",
        "æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¨ã®çµ„ã¿åˆã‚ã›",
        "é«˜åº¦ãªæ™‚ç³»åˆ—ç‰¹å¾´é‡",
        "ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–"
    ]
    for improvement in improvements:
        print(f"  â€¢ {improvement}")

if __name__ == "__main__":
    # æ€§èƒ½åˆ†æã®å®Ÿè¡Œ
    submission = analyze_submission_performance()
    
    # ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ
    generate_feature_importance_summary()
    
    # ç·åˆã‚µãƒãƒªãƒ¼
    model_performance_summary()
    
    # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    create_performance_plots()
    
    print(f"\nğŸ‰ æ€§èƒ½åˆ†æå®Œäº†ï¼")
    print(f"è©³ç´°ãªãƒ¬ãƒãƒ¼ãƒˆã¯ validation_report.md ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")